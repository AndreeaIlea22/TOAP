#A DSpace Implementation of ResourceSync for metadata harvesting

As part of the [Jisc]-funded work on the [ResourceSync project], we have been carrying out an experimental implementation of the standard against [DSpace] using the profile of ResourceSync we developed to meet the [OAI-PMH use case of metadata harvesting].  This post will describe the details of that implementation, highlighting design decisions, pointing out interesting features, and commenting on where the limitations of DSpace have been found when attempting to become ResourceSync-compliant.

##Generating ResourceSync documents

There are only 4 documents required in order to provide a basic metadata harvesting interface with ResourceSync:

* Capability List - providing links to the Resource List and Change List Archive
* Resource List - a full list of metadata records and bitstreams in DSpace, providing the initial baseline synchronisation data
* Change List Archive - a list of all of the periodically-generated Change Lists
* Change List - a list of all metadata records and bitstreams that have changed in DSpace in the time period.

[add diagram from previous post]

These documents are generated and kept up-to-date by a back-end process which can be set to run on a schedule (i.e. via cron).  All the documents are stored in the DSpace install directory as static files, and served statically so there are minimal performance implications.

The process of generating and updating these documents is as follows:

1. Initialise - creates a Capability List and a Resource List, where the Resource List is the current state of the resources in DSpace

2. Update - creates a new Change List which covers the period since the last Change List was created (or the initial Resource List was created), and adds it to the Change List Archive.  If the Change List Archive doesn't exist (because this is the first update since the initialise operation), then it is created, and added to the Capability List.

3. Rebase - Creates a new Resource List representing the current state of the resources, and a Change List which covers the period since the last Change List (just as in the update operation).

The DSpace administrator is responsible for running the Initialise operation when the system is ready to provide ResourceSync capabilities.  Then a scheduled task can be set to run the Update and Rebase operations regularly.  The Update operation will always generate a new Change List (even if there have been no changes in the period), and is a relatively quick operation because it only deals with a sub-set of the total content of the archive.  The Rebase operation should therefore be run much less frequently, as it will generate a document which itemises every DSpace item and every available bitstream in those items, which could be quite a substantial document.

As a result of this approach, a consumer of the ResourceSync documents will notice that there are Change Lists which cover periods prior to the last modified date of the Resource List (of which there is only ever one).  This enables both long-term consumers of the resources to remain in sync without ever needing to read the full Resource List (except for purposes of occasional audit), and for new consumers to carry out a baseline synchronisation to a point quite close to the true current state of the item; they would need to simply consume the few Change Lists generated since the Resource List was generated.

[add diagram showing how the historical change lists are kept, but there is only ever one resource list, and how the clients experience it]

A point worth pulling out is that the DSpace implementation can generate empty Change Lists; this can happen when there are no changes in the fixed period of time between the generation of the Change List documents.  We have taken the decision to generate a new Change List every time that the process runs, rather than attempting to append to existing Change Lists, for a couple of reasons:

* It saves DSpace from having to read in previous (potentially large) Change List documents, append some records to it, and write it out again.  There is both a reduction in complexity, and a gain in performance.
* It is convenient both for the client and the DSpace administrator to be able to see new Change Lists generated regularly, as it is predictable and easy to verify that it is behaving as expected.

Because of this decision, sometimes those Change Lists will be empty, and for the time being it is the plan to keep the behaviour this way.  We don't believe that this causes the client any particular problems.

##Declaring the metadata harvesting profile

1/ about link goes to a human-readable page
- DSpace admins can declare their own web pages to provide this

feedback: Clearer steer from the ResourceSync spec on what should be at that "describedby" link

##DSpace Bitstreams

9/ Can't detect if/when DSpace bitstreams changed
10/ Can't detect if/when DSpace bitstreams deleted
12/ Changefreq is probably always "never"
13/ Lastmod dates of bitstreams are actually the last mod dates of the parent item
14/ md5 hash only, and only one hash per item
15/ bitstream can be described by more than one metadata resource (single parent item, multiple formats)
    - how do you know that the metadata resources are equivalent items, and does it matter?
21/ can assert membership of 0 or more collections
25/ can configure which bundles are exposed

- bitstreams which are in more than one item?

##DSpace Items

11/ Can only announce an item is deleted if it is withdrawn
    - what happens to items which are withdrawn and then re-instated?
12/ Changefreq is probably always "never"
18/ Item metadata record urls are localised to the RS webapp, as the documents are generated on-the-fly
20/ Metadata record can describe multiple bitstreams
21/ can assert membership of 0 or more collections
23/ qdc format uses OAIDC crosswalk

##Retrieving Resources

23/ qdc format uses OAIDC crosswalk
19/ Metadata record formats are generated by plugins
8/ access to RS documents is unauthenticated
6/ access to bitstreams via normal url
7/ Publicly accessible resources only

##Declaring the metadata harvesting profile

1/ about link goes to a human-readable page
- DSpace admins can declare their own web pages to provide this

feedback: Clearer steer from the ResourceSync spec on what should be at that "describedby" link



##Sets/Collections

16/ "Sets" are the DSpace collections
17/ There is no equivalent "listsets" operation - should there be, and what would it look like?
22/ Collections are urls of UI's collection page

##Software

27/ Available as separate module
28/ has stand alone java lib backing it
29/ only for metadata harvesting use case, not more yet


